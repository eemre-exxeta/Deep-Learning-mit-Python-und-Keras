{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gymnasium\n",
    "#!pip install git+https://github.com/DLR-RM/stable-baselines3@feat/gymnasium-support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "TENSORBOARD_FOLDER = \"tensorboard_reinforcementlearning\"\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Bilder/rl_overview.png\" alt=\"Reinforcement Learning\" style=\"width:700px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset(seed=42)\n",
    "img = env.render()\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "for _ in range(500):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    position, velocity, angle, angular_velocity = observation\n",
    "\n",
    "    print(f\"Position: {position:+.2f} | \" + \n",
    "          f\"Velocity: {velocity:+.2f} | \" +\n",
    "          f\"Angle: {velocity:+.2f} | \" +\n",
    "          f\"Angular Velocity: {velocity:+.2f}\", end='\\r')\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policies\n",
    "## Hard-coded policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one_episode(env, policy, n_max_steps=200, seed=42):\n",
    "    frames = []\n",
    "    np.random.seed(seed)\n",
    "    obs, info = env.reset(seed=seed)\n",
    "    for step in range(n_max_steps):\n",
    "        frames.append(env.render())\n",
    "        action = policy(obs)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        if done or truncated:\n",
    "            break\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_policy(obs):\n",
    "    position, velocity, angle, angular_velocity = obs\n",
    "    return 0 if angle < 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "show_one_episode(env, basic_policy, n_max_steps=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximal Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "\n",
    "def ppo_cartpole_policy(obs):\n",
    "    action, _ = model_cartpole.predict(obs)\n",
    "    return action\n",
    "\n",
    "\n",
    "env = make_vec_env(\"CartPole-v1\", n_envs=4)\n",
    "\n",
    "model_cartpole = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=path.join(TENSORBOARD_FOLDER, \"ppo_CartPole\"))\n",
    "model_cartpole = model_cartpole.learn(total_timesteps=25000, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir ./ppo_cartpole_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "show_one_episode(env, ppo_cartpole_policy, n_max_steps=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CarRacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CarRacing-v2\", render_mode=\"human\")\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "for _ in range(500):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_carracing_policy(obs):\n",
    "    action, _ = model_carracing.predict(obs)\n",
    "    return action\n",
    "\n",
    "\n",
    "env = make_vec_env(\"CarRacing-v2\", n_envs=4)\n",
    "\n",
    "model_carracing = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=path.join(TENSORBOARD_FOLDER, \"ppo_CarRacing\"))\n",
    "# model_carracing = model_carracing.learn(total_timesteps=25000, progress_bar=True)\n",
    "\n",
    "model_carracing = model_carracing.load(\"model_carracing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CarRacing-v2\", render_mode=\"human\")\n",
    "show_one_episode(env, ppo_carracing_policy, n_max_steps=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besseres Modell hier zu finden: https://huggingface.co/meln1k/ppo-CarRacing-v0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
